{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/seetha/.local/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 100/1000 - Total reward: 0.0 - Epsilon: 0.6057704364907278\n",
      "Q-table snapshot:\n",
      "[[9.27511024e-03 2.01158702e-02 3.40658858e-03 9.68163730e-03]\n",
      " [8.14773730e-03 0.00000000e+00 1.79446270e-05 9.36267024e-04]\n",
      " [1.16384216e-04 0.00000000e+00 5.46316752e-07 1.67596645e-07]\n",
      " [5.51835103e-06 0.00000000e+00 0.00000000e+00 5.46316752e-07]\n",
      " [9.56851160e-03 2.78119256e-02 0.00000000e+00 5.18742410e-03]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 3.37056390e-03 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [1.36302423e-02 0.00000000e+00 4.71395236e-02 1.27754813e-02]\n",
      " [3.33173744e-04 1.02032678e-01 2.56337725e-02 0.00000000e+00]\n",
      " [4.81818842e-03 2.12789433e-01 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 4.33204200e-03 2.71489961e-01 1.38131403e-02]\n",
      " [2.36530939e-02 2.58686039e-01 6.86189404e-01 1.82667979e-02]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n",
      "Episode 200/1000 - Total reward: 0.0 - Epsilon: 0.3669578217261671\n",
      "Q-table snapshot:\n",
      "[[4.75903993e-01 7.49010520e-01 1.08968200e-01 2.16345659e-01]\n",
      " [2.93860749e-01 0.00000000e+00 2.76722017e-05 2.18621010e-02]\n",
      " [1.16384216e-04 3.33685826e-04 1.03800183e-06 1.67596645e-07]\n",
      " [1.64885533e-05 0.00000000e+00 0.00000000e+00 5.46316752e-07]\n",
      " [2.16787332e-01 8.04155505e-01 0.00000000e+00 3.74364254e-01]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 7.70269281e-02 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [1.92931075e-01 0.00000000e+00 8.75561563e-01 3.53039735e-01]\n",
      " [2.09284681e-01 9.35367889e-01 4.12572662e-01 0.00000000e+00]\n",
      " [2.49810404e-01 7.91537773e-01 0.00000000e+00 9.04288589e-04]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 4.81094420e-01 9.72286684e-01 4.56249525e-01]\n",
      " [4.20329049e-01 5.02949984e-01 9.96956747e-01 4.77271317e-01]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n",
      "Episode 300/1000 - Total reward: 0.0 - Epsilon: 0.22229219984074702\n",
      "Q-table snapshot:\n",
      "[[7.39720596e-01 9.47680188e-01 2.13959996e-01 6.44910070e-01]\n",
      " [5.05003360e-01 0.00000000e+00 2.76722017e-05 4.87681050e-02]\n",
      " [1.16384216e-04 3.33685826e-04 1.03800183e-06 1.67596645e-07]\n",
      " [1.64885533e-05 0.00000000e+00 0.00000000e+00 5.46316752e-07]\n",
      " [7.12160860e-01 9.58977365e-01 0.00000000e+00 6.29929941e-01]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 1.47686475e-01 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [4.48523947e-01 0.00000000e+00 9.69683652e-01 3.97967396e-01]\n",
      " [4.03791478e-01 9.79927268e-01 5.82998465e-01 0.00000000e+00]\n",
      " [2.49810404e-01 8.94844389e-01 0.00000000e+00 8.43952561e-03]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 7.40141416e-01 9.89963557e-01 7.45227913e-01]\n",
      " [7.61701677e-01 5.51654591e-01 9.99996412e-01 5.75802517e-01]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n",
      "Episode 400/1000 - Total reward: 1.0 - Epsilon: 0.1346580429260134\n",
      "Q-table snapshot:\n",
      "[[8.44637621e-01 9.50984449e-01 3.97224070e-01 7.83404753e-01]\n",
      " [7.09277572e-01 0.00000000e+00 2.76722017e-05 4.87681050e-02]\n",
      " [1.16384216e-04 3.33685826e-04 1.03800183e-06 1.67596645e-07]\n",
      " [1.64885533e-05 0.00000000e+00 0.00000000e+00 5.46316752e-07]\n",
      " [8.58269357e-01 9.60594199e-01 0.00000000e+00 7.36860156e-01]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 1.47686475e-01 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [5.87275602e-01 0.00000000e+00 9.70298506e-01 5.88109529e-01]\n",
      " [4.59471859e-01 9.80099875e-01 7.23842709e-01 0.00000000e+00]\n",
      " [2.49810404e-01 9.56821261e-01 0.00000000e+00 8.43952561e-03]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 8.38406651e-01 9.89999983e-01 8.37389805e-01]\n",
      " [8.03197304e-01 6.70446024e-01 9.99999999e-01 7.14936955e-01]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n",
      "Episode 500/1000 - Total reward: 1.0 - Epsilon: 0.0996820918179746\n",
      "Q-table snapshot:\n",
      "[[8.70881803e-01 9.50990047e-01 4.57465412e-01 8.26243120e-01]\n",
      " [7.53396036e-01 0.00000000e+00 2.76722017e-05 4.87681050e-02]\n",
      " [1.16384216e-04 3.33685826e-04 1.03800183e-06 1.67596645e-07]\n",
      " [1.64885533e-05 0.00000000e+00 0.00000000e+00 5.46316752e-07]\n",
      " [8.83396634e-01 9.60596009e-01 0.00000000e+00 7.75737946e-01]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 1.47686475e-01 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [6.88445429e-01 0.00000000e+00 9.70299000e-01 6.24397581e-01]\n",
      " [5.09584274e-01 9.80100000e-01 7.23842709e-01 0.00000000e+00]\n",
      " [3.21859263e-01 9.63125221e-01 0.00000000e+00 8.43952561e-03]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 9.04798345e-01 9.90000000e-01 8.50680723e-01]\n",
      " [8.51137935e-01 7.80340636e-01 1.00000000e+00 7.78814331e-01]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n",
      "Episode 600/1000 - Total reward: 1.0 - Epsilon: 0.0996820918179746\n",
      "Q-table snapshot:\n",
      "[[9.03961293e-01 9.50990050e-01 5.66383455e-01 8.48138155e-01]\n",
      " [8.18078163e-01 0.00000000e+00 2.76722017e-05 4.87681050e-02]\n",
      " [1.16384216e-04 3.33685826e-04 1.03800183e-06 1.67596645e-07]\n",
      " [1.64885533e-05 0.00000000e+00 0.00000000e+00 5.46316752e-07]\n",
      " [9.01714450e-01 9.60596010e-01 0.00000000e+00 8.07228964e-01]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 1.47686475e-01 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [7.82038014e-01 0.00000000e+00 9.70299000e-01 7.12904140e-01]\n",
      " [5.95276504e-01 9.80100000e-01 7.87857612e-01 0.00000000e+00]\n",
      " [3.21859263e-01 9.74130712e-01 0.00000000e+00 8.43952561e-03]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 9.30694584e-01 9.90000000e-01 8.99665604e-01]\n",
      " [8.75640727e-01 8.37158324e-01 1.00000000e+00 8.12508977e-01]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n",
      "Episode 700/1000 - Total reward: 1.0 - Epsilon: 0.0996820918179746\n",
      "Q-table snapshot:\n",
      "[[9.03961293e-01 9.50990050e-01 6.35796432e-01 8.80238467e-01]\n",
      " [8.51520101e-01 0.00000000e+00 2.76722017e-05 4.87681050e-02]\n",
      " [1.16384216e-04 3.33685826e-04 1.03800183e-06 1.67596645e-07]\n",
      " [1.64885533e-05 0.00000000e+00 0.00000000e+00 5.46316752e-07]\n",
      " [9.11076814e-01 9.60596010e-01 0.00000000e+00 8.53397947e-01]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 1.47686475e-01 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [8.43444109e-01 0.00000000e+00 9.70299000e-01 7.58140463e-01]\n",
      " [7.20909882e-01 9.80100000e-01 7.87857612e-01 0.00000000e+00]\n",
      " [3.21859263e-01 9.80629344e-01 0.00000000e+00 8.43952561e-03]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 9.30694584e-01 9.90000000e-01 9.18807254e-01]\n",
      " [8.95487989e-01 8.89720576e-01 1.00000000e+00 8.75985316e-01]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n",
      "Episode 800/1000 - Total reward: 1.0 - Epsilon: 0.0996820918179746\n",
      "Q-table snapshot:\n",
      "[[9.11089876e-01 9.50990050e-01 6.76056646e-01 9.08933809e-01]\n",
      " [8.68612510e-01 0.00000000e+00 2.76722017e-05 4.87681050e-02]\n",
      " [1.16384216e-04 3.33685826e-04 1.03800183e-06 1.67596645e-07]\n",
      " [1.64885533e-05 0.00000000e+00 0.00000000e+00 5.46316752e-07]\n",
      " [9.18660329e-01 9.60596010e-01 0.00000000e+00 8.77268224e-01]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 1.47686475e-01 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [8.55159299e-01 0.00000000e+00 9.70299000e-01 7.94781884e-01]\n",
      " [7.44878495e-01 9.80100000e-01 8.37986545e-01 0.00000000e+00]\n",
      " [3.21859263e-01 9.84466721e-01 0.00000000e+00 8.43952561e-03]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 9.44083452e-01 9.90000000e-01 9.23956429e-01]\n",
      " [9.18417844e-01 9.08773667e-01 1.00000000e+00 9.01946096e-01]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n",
      "Episode 900/1000 - Total reward: 1.0 - Epsilon: 0.0996820918179746\n",
      "Q-table snapshot:\n",
      "[[9.21541091e-01 9.50990050e-01 7.55651903e-01 9.20126495e-01]\n",
      " [8.93671691e-01 0.00000000e+00 5.79398783e-05 4.87681050e-02]\n",
      " [1.16384216e-04 1.49212783e-02 1.03800183e-06 1.67596645e-07]\n",
      " [1.64885533e-05 0.00000000e+00 0.00000000e+00 5.46316752e-07]\n",
      " [9.21893301e-01 9.60596010e-01 0.00000000e+00 9.03563649e-01]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 2.30434812e-01 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [8.75192274e-01 0.00000000e+00 9.70299000e-01 8.10402701e-01]\n",
      " [8.19063748e-01 9.80100000e-01 8.64135678e-01 0.00000000e+00]\n",
      " [3.86703237e-01 9.86369616e-01 0.00000000e+00 8.43952561e-03]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 9.50926596e-01 9.90000000e-01 9.32761517e-01]\n",
      " [9.24586060e-01 9.36707403e-01 1.00000000e+00 9.15996654e-01]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n",
      "Episode 1000/1000 - Total reward: 0.0 - Epsilon: 0.0996820918179746\n",
      "Q-table snapshot:\n",
      "[[9.26944576e-01 9.50990050e-01 7.68560211e-01 9.24183689e-01]\n",
      " [8.98452537e-01 0.00000000e+00 5.79398783e-05 4.87681050e-02]\n",
      " [1.16384216e-04 1.49212783e-02 1.03800183e-06 1.67596645e-07]\n",
      " [1.64885533e-05 0.00000000e+00 0.00000000e+00 5.46316752e-07]\n",
      " [9.29778520e-01 9.60596010e-01 0.00000000e+00 9.10767784e-01]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 2.30434812e-01 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [8.98336686e-01 0.00000000e+00 9.70299000e-01 8.58750690e-01]\n",
      " [8.33216975e-01 9.80100000e-01 8.85521965e-01 0.00000000e+00]\n",
      " [4.45062813e-01 9.87059389e-01 0.00000000e+00 8.43952561e-03]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 9.58832588e-01 9.90000000e-01 9.36515265e-01]\n",
      " [9.30137454e-01 9.51149697e-01 1.00000000e+00 9.22083521e-01]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n",
      "Average reward over 100 evaluation episodes: 1.0\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Initialize the FrozenLake environment\n",
    "env = gym.make(\"FrozenLake-v1\", is_slippery=False)\n",
    "\n",
    "# Q-learning parameters\n",
    "alpha = 0.1  # Learning rate\n",
    "gamma = 0.99  # Discount factor\n",
    "epsilon = 1.0  # Exploration rate\n",
    "epsilon_min = 0.1  # Minimum exploration rate\n",
    "epsilon_decay = 0.995  # Decay rate for exploration probability\n",
    "\n",
    "# Initialize the Q-table\n",
    "q_table = np.zeros((env.observation_space.n, env.action_space.n))\n",
    "\n",
    "# Training parameters\n",
    "num_episodes = 1000\n",
    "max_steps_per_episode = 100\n",
    "\n",
    "# Q-learning algorithm\n",
    "for episode in range(num_episodes):\n",
    "    state, _ = env.reset()\n",
    "    done = False\n",
    "    step = 0\n",
    "    total_reward = 0\n",
    "    \n",
    "    while not done and step < max_steps_per_episode:\n",
    "        # Exploration-exploitation tradeoff\n",
    "        if random.uniform(0, 1) < epsilon:\n",
    "            action = env.action_space.sample()  # Explore\n",
    "        else:\n",
    "            action = np.argmax(q_table[state, :])  # Exploit\n",
    "        \n",
    "        # Take the action and observe the outcome\n",
    "        next_state, reward, done, _, _ = env.step(action)\n",
    "        \n",
    "        # Update the Q-table\n",
    "        old_value = q_table[state, action]\n",
    "        next_max = np.max(q_table[next_state, :])\n",
    "        new_value = (1 - alpha) * old_value + alpha * (reward + gamma * next_max)\n",
    "        q_table[state, action] = new_value\n",
    "        \n",
    "        state = next_state\n",
    "        step += 1\n",
    "        total_reward += reward\n",
    "    \n",
    "    # Decay the exploration rate\n",
    "    if epsilon > epsilon_min:\n",
    "        epsilon *= epsilon_decay\n",
    "    \n",
    "    if (episode + 1) % 100 == 0:\n",
    "        print(f'Episode {episode + 1}/{num_episodes} - Total reward: {total_reward} - Epsilon: {epsilon}')\n",
    "        print(f'Q-table snapshot:\\n{q_table}')\n",
    "\n",
    "# Evaluate the agent\n",
    "num_eval_episodes = 100\n",
    "total_rewards = 0\n",
    "\n",
    "for episode in range(num_eval_episodes):\n",
    "    state, _ = env.reset()\n",
    "    done = False\n",
    "    step = 0\n",
    "    episode_reward = 0\n",
    "    \n",
    "    while not done and step < max_steps_per_episode:\n",
    "        action = np.argmax(q_table[state, :])  # Always exploit during evaluation\n",
    "        next_state, reward, done, _, _ = env.step(action)\n",
    "        episode_reward += reward\n",
    "        state = next_state\n",
    "        step += 1\n",
    "    \n",
    "    total_rewards += episode_reward\n",
    "\n",
    "average_reward = total_rewards / num_eval_episodes\n",
    "print(f'Average reward over {num_eval_episodes} evaluation episodes: {average_reward}')\n",
    "env.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
